
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    [{"authors":null,"categories":null,"content":"Researcher at the Department of Cultural Heritage of the University of Bologna. Graduated in 2020 with a master’s degree in Digital Humanities and Digital Knowledge (DHDK) from the University of Bologna, I currently work at the FrameLAB research laboratory on various projects related to the application of Linked Open Data methodologies and technologies. Specifically, my research interests focus on the study and implementation of tools and methodologies based on Linked Open Data and Open Science to enhance academic activities (research, teaching, and public engagement) in the fields of humanities and cultural heritage.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"","publishdate":"0001-01-01T00:00:00Z","relpermalink":"","section":"authors","summary":"Researcher at the Department of Cultural Heritage of the University of Bologna. Graduated in 2020 with a master’s degree in Digital Humanities and Digital Knowledge (DHDK) from the University of Bologna, I currently work at the FrameLAB research laboratory on various projects related to the application of Linked Open Data methodologies and technologies. Specifically, my research interests focus on the study and implementation of tools and methodologies based on Linked Open Data and Open Science to enhance academic activities (research, teaching, and public engagement) in the fields of humanities and cultural heritage.\n","tags":null,"title":"Sebastian Barzaghi","type":"authors"},{"authors":[],"categories":null,"content":" Click on the Slides button above to view the built-in slides feature. Slides can be added in a few ways:\nCreate slides using Hugo Blox Builder’s Slides feature and link using slides parameter in the front matter of the talk file Upload an existing slide deck to static/ and link using url_slides parameter in the front matter of the talk file Embed your slides (e.g. Google Slides) or presentation video on this page using shortcodes. Further event details, including page elements such as image galleries, can be added to the body of this page.\n","date":1906549200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1906549200,"objectID":"a8edef490afe42206247b6ac05657af0","permalink":"http://localhost:1313/talk/example-talk/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/talk/example-talk/","section":"event","summary":"An example talk using Hugo Blox Builder's Markdown slides feature.","tags":[],"title":"Example Talk","type":"event"},{"authors":["Sebastian Barzaghi","Ivan Heibi","Arianna Moretti","Silvio Peroni"],"categories":null,"content":"","date":1735689600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1735689600,"objectID":"b84f4aa7c3c61d88377c07ec67674893","permalink":"http://localhost:1313/publication/barzaghi-developing-2025/","publishdate":"2025-02-13T15:40:36.688626Z","relpermalink":"/publication/barzaghi-developing-2025/","section":"publication","summary":"As a result of the proliferation of 3D digitisation in the context of cultural heritage projects, digital assets and digitisation processes - being considered as proper research objects - must prioritise adherence to FAIR principles. Existing standards and ontologies, such as CIDOC-CRM, play a crucial role in this regard, but they are often over-engineered for the need of a particular application context, thus making their understanding and adoption difficult. Application profiles of a given standard - defined as sets of ontological entities drawn from one or more semantic artefacts for a particular context or application - are usually proposed as tools for promoting interoperability and reuse while being tied entirely to the particular application context they refer to. In this paper, we present an adaptation and application of an ontology development methodology, i.e. SAMOD, to guide the creation of robust, semantically sound application profiles of large standard models. Using an existing pilot study we have developed in a project dedicated to leveraging virtual technologies to preserve and valorise cultural heritage, we introduce an application profile named CHAD-AP, that we have developed following our customised version of SAMOD. We reflect on the use of SAMOD and similar ontology development methodologies for this purpose, highlighting its strengths and current limitations, future developments, and possible adoption in other similar projects.","tags":["cultural heritage","OWL","FAIR principles","ontology development","3D digitisation","application profiles"],"title":"Developing Application Profiles for Enhancing Data and Workflows in Cultural Heritage Digitisation Processes","type":"publication"},{"authors":["Sebastian Barzaghi","Alice Bordignon","Bianca Gualandi","Ivan Heibi","Arcangelo Massari","Arianna Moretti","Silvio Peroni","Giulia Renda"],"categories":null,"content":"","date":1733011200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1733011200,"objectID":"42dcd0148ee05696740de5cbdfcf85d8","permalink":"http://localhost:1313/publication/barzaghi-proposal-2024/","publishdate":"2025-02-13T15:40:36.703842Z","relpermalink":"/publication/barzaghi-proposal-2024/","section":"publication","summary":"In this article we analyse 3D models of cultural heritage with the aim of answering three main questions. What processes can be put in place to create a FAIR-by-design digital twin of a temporary exhibition? What are the main challenges in applying FAIR principles to 3D data in cultural heritage studies and how are they different from other types of data (e.g. images) from a data management perspective? We begin with a comprehensive literature review touching on FAIR principles applied to cultural heritage data; representation models; both Object Provenance Information (OPI) and Metadata Record Provenance Information (MRPI), respectively meant as, on the one hand, the detailed history and origin of an object, and - on the other hand - the detailed history and origin of the metadata itself, which describes the primary object (whether physical or digital); 3D models as cultural heritage research data and their creation, selection, publication, archival and preservation. We then describe the process of creating the Aldrovandi Digital Twin, by collecting, storing and modelling data about cultural heritage objects and processes. We detail the many steps from the acquisition of the Digital Cultural Heritage Objects (DCHO), through to the upload of the optimised DCHO onto a web-based framework (ATON), with a focus on open technologies and standards for interoperability and preservation. Using the FAIR Principles for Heritage Library, Archive and Museum Collections [1] as a framework, we look in detail at how the Digital Twin implements FAIR principles at the object and metadata level. We then describe the main challenges we encountered and we summarise what seem to be the peculiarities of 3D cultural heritage data and the possible directions for further research in this field.","tags":null,"title":"A Proposal for a FAIR Management of 3D Data in Cultural Heritage: The Aldrovandi Digital Twin Case","type":"publication"},{"authors":["Barzaghi Sebastian","Alice Bordignon","Federica Collina","Francesca Fabbri","Bruno Fanini","Daniele Ferdani","Bianca Gualandi","Ivan Heibi","Nicola Mariniello","Arcangelo Massari","Marcello Massidda","Arianna Moretti","Silvio Peroni","Sofia Pescarin","Maria Felicia Rega","Giulia Renda","Mattia Sullini"],"categories":null,"content":"","date":1730419200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1730419200,"objectID":"5fd39efe9c3c39f82ffd15378b1baeb6","permalink":"http://localhost:1313/publication/sebastian-reproducible-2024/","publishdate":"2025-02-13T15:40:36.731988Z","relpermalink":"/publication/sebastian-reproducible-2024/","section":"publication","summary":"This article explores how to create reproducible workflows for the 3D acquisition and digitisation of cultural heritage objects to ensure sustainability and reusability across various institutions. By addressing two main research questions, the paper proposes a workflow that involves the systematic acquisition, processing, and digitisation of cultural heritage artefacts. In particular, the workflow focuses on developing digital twins for cultural heritage settings and exhibitions and proposes baseline standards for both technical and interpretative aspects of digitisation. The workflow has been derived and tested on the pilot case of the temporary exhibition The Other Renaissance: Ulisse Aldrovandi and the Wonders of the World in the context of the CHANGES project. We reflect on the software and hardware equipment, the procedures and techniques to use, and the formats to adopt to comply with openness, accessibility, transparency, reproducibility, reusability and sustainability of the research workflow by backing on previous works on fostering reproducibility in research and improving the interoperability of 3D data across different systems. It highlights the necessity for transparent documentation of every step of the process, focusing on accountability and practices in the context of cultural heritage research. Finally, the article suggests improvements to enhance the sustainability of these kinds of workflows and discusses future directions for digitisation efforts and sharing research practices.","tags":null,"title":"A reproducible workflow for the creation of digital twins in the cultural heritage domain","type":"publication"},{"authors":["Sebastian Barzaghi","Francesco Paolucci","Francesca Tomasi","Fabio Vitali"],"categories":null,"content":"","date":1727740800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1727740800,"objectID":"d455a4c704d1ab4506beb168ea27a72a","permalink":"http://localhost:1313/publication/barzaghi-kwickwockwac-2024/","publishdate":"2025-02-13T15:40:36.724541Z","relpermalink":"/publication/barzaghi-kwickwockwac-2024/","section":"publication","summary":"This paper introduces KwicKwocKwac 1.0 (KwicKK), a web application designed to enhance the annotation and enrichment of digital texts in the humanities. KwicKK provides a user-friendly interface that enables scholars and researchers to perform semi-automatic markup of textual documents, facilitating the identification of relevant entities such as people, organizations, and locations. Key functionalities include the visualization of annotated texts using KeyWord in Context (KWIC), KeyWord Out Of Context (KWOC), and KeyWord After Context (KWAC) methodologies, alongside automatic disambiguation of generic references and integration with Wikidata for Linked Open Data connections. The application supports metadata input and offers multiple download formats, promoting accessibility and ease of use. Developed primarily for the National Edition of Aldo Moro's works, KwicKK aims to lower the technical barriers for users while fostering deeper engagement with digital scholarly resources. The architecture leverages contemporary web technologies, ensuring scalability and reliability. Future developments will explore user experience enhancements, collaborative features, and integration of additional data sources.","tags":["Computer Science - Digital Libraries","Computer Science - Information Retrieval"],"title":"KwicKwocKwac, a tool for rapidly generating concordances and marking up a literary text","type":"publication"},{"authors":["Sebastian Barzaghi"],"categories":["Digital Humanities"],"content":"Humanities Data Cleaning A soft introduction to Data Cleaning with OpenRefine Sebastian Barzaghi | sebastian.barzaghi2@unibo.it | https://orcid.org/0000-0002-0799-1527\nWhat is humanities data? Any value assigned to something that can be quantified, qualified or interpreted in some way to be used as an informative evidence\nNumbers, words, images, videos, photos, audio records, interviews, manuscripts, notes, collections…\nGualandi, B., Pareschi, L., \u0026amp; Peroni, S. (2023). What do we mean by “data”? A proposed classification of data types in the arts and humanities. Journal of Documentation, 79(7), 51-71. https://doi.org/10.1108/JD-07-2022-0146. To be useful, data should be organized To be understood by yourself in the future\nTo be machine-readable (Interoperable in FAIR)\nTo be understood by others (Reusable in FAIR)\nUiT The Arctic University of Norway. (2023). Data Cleaning. Zenodo. https://doi.org/10.5281/zenodo.8375643 All data is messy Never take your data at face value\n80% of data analysis is spent on the process of cleaning data and preparing it for further manipulation and analysis\nCleaning and preparation must be iterative\nNecessary for working with datasets\nUiT The Arctic University of Norway. (2023). Data Cleaning. Zenodo. https://doi.org/10.5281/zenodo.8375643 A dataset is a collection of data Every value belongs to a variable and an observation\nEvery variable forms a column\nEvery observation forms a row\nS. Ciston, “A CRITICAL FIELD GUIDE FOR WORKING WITH MACHINE LEARNING DATASETS”, K. Crawford and M. Ananny, Eds., Knowing Machines project, Feb. 2023. https://knowingmachines.org/critical-field-guide. Data cleaning is hard (but worth it)! Prepare the data Eliminate redundancy Separate or combine values Fix errors and inconsistencies (e.g. duplicates, empty values, inconsistent spelling or formatting, etc.) Standardize when possible Treat NULL values UiT The Arctic University of Norway. (2023). Data Cleaning. Zenodo. https://doi.org/10.5281/zenodo.8375643 Common mistakes Never modify your original data Always make a copy before making changes\nBack up your files\nKeep track of all the steps\nSave your files in the UTF-8 encoding\nSeth van Hooland, Ruben Verborgh, and Max De Wilde, \u0026#34;Cleaning Data with OpenRefine,\u0026#34; Programming Historian 2 (2013), https://doi.org/10.46430/phen0023. Always describe your data Document everything necessary to understand what is in the dataset and how to use it\nConsider:\nThe who, what, when, where, and how of data collection How to find and access the data Suggestions on the suitability of the data for answering specific questions Warnings about known problems or inconsistencies in the data Information to check that the data are properly imported White, E. P., Baldridge, E., Brym, Z. T., Locey, K. J., McGlinn, D. J., \u0026amp; Supp, S. R. (2013). Nine simple ways to make it easier to (re)use your data (e7v2). PeerJ Inc. https://doi.org/10.7287/peerj.preprints.7v2. Use standard table formats Every variable must have a separate column\nUiT The Arctic University of Norway. (2023). Data Cleaning. Zenodo. https://doi.org/10.5281/zenodo.8375643 Use standard table formats Every observation must have a separate row\nUiT The Arctic University of Norway. (2023). Data Cleaning. Zenodo. https://doi.org/10.5281/zenodo.8375643 Use standard table formats Every cell should contain a single data value\nUiT The Arctic University of Norway. (2023). Data Cleaning. Zenodo. https://doi.org/10.5281/zenodo.8375643 Avoid aggregating comments and other information with data Examples: comments placed within data cells, measurement units included in data cells, entering more than one type of information in a cell, including metadata in the table, etc.\nUiT The Arctic University of Norway. (2023). Data Cleaning. Zenodo. https://doi.org/10.5281/zenodo.8375643 Avoid aggregating comments and other information with data Add units to the column title or into a separate column\nAdd information to a separate column\nAdd metadata in a separate document\nUiT The Arctic University of Norway. (2023). Data Cleaning. Zenodo. https://doi.org/10.5281/zenodo.8375643 Do not use formatting to convey information Example: highlighting cells, rows or columns that should be excluded from an analysis, leaving blank rows to indicate separations in data.\nUiT The Arctic University of Norway. (2023). Data Cleaning. Zenodo. https://doi.org/10.5281/zenodo.8375643 Do not use formatting to convey information Add units to the column title or into a separate column\nAdd information to a separate column\nAdd metadata in a separate document\nUiT The Arctic University of Norway. (2023). Data Cleaning. Zenodo. https://doi.org/10.5281/zenodo.8375643 Do not use multiple tables nor tabs Multiple data tables or tabs within a single spreadsheet\nIf possible, combine everything into one table, or store each table in a separate file\nUiT The Arctic University of Norway. (2023). Data Cleaning. Zenodo. https://doi.org/10.5281/zenodo.8375643 Do not use special characters …","date":1719792000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1719792000,"objectID":"aba5a898245acb7e441862b8a2de52bc","permalink":"http://localhost:1313/slides/data-cleaning-openrefine/","publishdate":"2024-07-01T00:00:00Z","relpermalink":"/slides/data-cleaning-openrefine/","section":"slides","summary":"A soft introduction to Data Cleaning with OpenRefine","tags":["Digital Humanities"],"title":"Cleaning data with OpenRefine","type":"slides"},{"authors":["Sebastian Barzaghi","Alice Bordignon","Bianca Gualandi","Silvio Peroni"],"categories":null,"content":"","date":1717200000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1717200000,"objectID":"9bc419be8ac659087fae615ff7f964d9","permalink":"http://localhost:1313/publication/barzaghi-thinking-2024/","publishdate":"2025-02-13T15:40:36.740165Z","relpermalink":"/publication/barzaghi-thinking-2024/","section":"publication","summary":"One of the main goals of Open Science is to make research more reproducible. There is no consensus, however, on what exactly “reproducibility” is, as opposed for example to “replicability”, and how it applies to different research fields. After a short review of the literature on reproducibility/replicability with a focus on the humanities, we describe how the creation of the digital twin of the temporary exhibition “The Other Renaissance” has been documented throughout, with different methods, but with constant attention to research transparency, openness and accountability. A careful documentation of the study design, data collection and analysis techniques helps reflect and make all possible influencing factors explicit, and is a fundamental tool for reliability and rigour and for opening the “black box” of research.","tags":null,"title":"Thinking Outside the Black Box: Insights from a Digital Exhibition in the Humanities","type":"publication"},{"authors":null,"categories":null,"content":"","date":1713225600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1713225600,"objectID":"b2ee8cce7f89d02dc0bb6b71d07e3722","permalink":"http://localhost:1313/project/chad-ap/","publishdate":"2024-04-16T00:00:00Z","relpermalink":"/project/chad-ap/","section":"project","summary":"The Cultural Heritage Acquisition and Digitisation Application Profile (CHAD-AP) is a CIDOC CRM application profile implemented as an OWL 2 DL ontology for describing cultural heritage digitisation data and processes in a FAIR-compliant and machine-readable format.","tags":["Knowledge Management","Data Documentation"],"title":"Cultural Heritage Acquisition and Digitisation Application Profile (CHAD-AP)","type":"project"},{"authors":["Sebastian Barzaghi","Ivan Heibi","Arianna Moretti","Silvio Peroni"],"categories":null,"content":"","date":1711929600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1711929600,"objectID":"5cf4b0e6a0dd38c9f9a18ff4d89af0ac","permalink":"http://localhost:1313/publication/barzaghi-developing-2024/","publishdate":"2025-02-13T15:40:36.747101Z","relpermalink":"/publication/barzaghi-developing-2024/","section":"publication","summary":"As a result of the proliferation of 3D digitisation in the context of cultural heritage projects, digital assets and digitisation processes - being considered as proper research objects - must prioritise adherence to FAIR principles. Existing standards and ontologies, such as CIDOC CRM, play a crucial role in this regard, but they are often over-engineered for the need of a particular application context, thus making their understanding and adoption difficult. Application profiles of a given standard - defined as sets of ontological entities drawn from one or more semantic artefacts for a particular context or application - are usually proposed as tools for promoting interoperability and reuse while being tied entirely to the particular application context they refer to. In this paper, we present an adaptation and application of an ontology development methodology, i.e. SAMOD, to guide the creation of robust, semantically sound application profiles of large standard models. Using an existing pilot study we have developed in a project dedicated to leveraging virtual technologies to preserve and valorise cultural heritage, we introduce an application profile named CHAD-AP, that we have developed following our customised version of SAMOD. We reflect on the use of SAMOD and similar ontology development methodologies for this purpose, highlighting its strengths and current limitations, future developments, and possible adoption in other similar projects.","tags":["Computer Science - Digital Libraries"],"title":"Developing Application Profiles for Enhancing Data and Workflows in Cultural Heritage Digitisation Processes","type":"publication"},{"authors":["Sebastian Barzaghi","Alice Bordignon","Bianca Gualandi","Silvio Peroni"],"categories":null,"content":"","date":1711929600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1711929600,"objectID":"4965616c48721dc964c2479f48495b1c","permalink":"http://localhost:1313/publication/barzaghi-thinking-2024-1/","publishdate":"2025-02-13T15:40:36.754697Z","relpermalink":"/publication/barzaghi-thinking-2024-1/","section":"publication","summary":"One of the main goals of Open Science is to make research more reproducible. There is no consensus, however, on what exactly \\\"reproducibility\\\" is, as opposed for example to \\\"replicability\\\", and how it applies to different research fields. After a short review of the literature on reproducibility/replicability with a focus on the humanities, we describe how the creation of the digital twin of the temporary exhibition \\\"The Other Renaissance\\\" has been documented throughout, with different methods, but with constant attention to research transparency, openness and accountability. A careful documentation of the study design, data collection and analysis techniques helps reflect and make all possible influencing factors explicit, and is a fundamental tool for reliability and rigour and for opening the \\\"black box\\\" of research.","tags":["Computer Science - Digital Libraries"],"title":"Thinking Outside the Black Box: Insights from a Digital Exhibition in the Humanities","type":"publication"},{"authors":["Roberto Balzani","Sebastian Barzaghi","Gabriele Bitelli","Federica Bonifazi","Alice Bordignon","Luca Cipriani","Simona Colitti","Federica Collina","Marilena Daquino","Francesca Fabbri","Bruno Fanini","Filippo Fantini","Daniele Ferdani","Giulia Fiorini","Elena Formia","Anna Forte","Federica Giacomini","Valentina Alena Girelli","Bianca Gualandi","Ivan Heibi","Alessandro Iannucci","Rachele Manganelli Del Fà","Arcangelo Massari","Arianna Moretti","Silvio Peroni","Sofia Pescarin","Giulia Renda","Diego Ronchi","Mattia Sullini","Maria Alessandra Tini","Francesca Tomasi","Laura Travaglini","Luca Vittuari"],"categories":null,"content":"","date":1709251200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1709251200,"objectID":"27c03f5a574f3f32df7b9fcaa99e6f6c","permalink":"http://localhost:1313/publication/balzani-saving-2024/","publishdate":"2025-02-13T15:40:36.76188Z","relpermalink":"/publication/balzani-saving-2024/","section":"publication","summary":"As per the objectives of Project CHANGES, particularly its thematic sub-project on the use of virtual technologies for museums and art collections, our goal was to obtain a digital twin of the temporary exhibition on Ulisse Aldrovandi called “The Other Renaissance”, and make it accessible to users online. After a preliminary study of the exhibition, focusing on acquisition constraints and related solutions, we proceeded with the digital twin creation by acquiring, processing, modelling, optimising, exporting, and metadating the exhibition. We made hybrid use of two acquisition techniques to create new digital cultural heritage objects and environments, and we used open technologies, formats, and protocols to make available the final digital product. Here, we describe the process of collecting and curating bibliographical exhibition (meta) data and the beginning of the digital twin creation to foster its findability, accessibility, interoperability, and reusability. The creation of the digital twin is currently ongoing.","tags":["Digital cultural heritage objects","Digital twins","Photogrammetry","Preservation of temporary exhibitions","Structured light projection scanning"],"title":"Saving temporary exhibitions in virtual environments: The Digital Renaissance of Ulisse Aldrovandi - Acquisition and digitisation of cultural heritage objects","type":"publication"},{"authors":["Sebastian Barzaghi"],"categories":null,"content":"","date":1704067200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1704067200,"objectID":"643d1d027d3e2ef4ebb803fa642f6527","permalink":"http://localhost:1313/publication/barzaghi-hero-nodate/","publishdate":"2025-02-13T15:40:36.710741Z","relpermalink":"/publication/barzaghi-hero-nodate/","section":"publication","summary":"In recent decades there has been a change in perspective towards risk assessment in cultural and environmental heritage. Despite the positive impact of heritage on various aspects of society, it is often neglected in disaster risk management, mostly due to lack of strategies in sharing common methodologies and process knowledge. The SIRIUS project, centered in Ravenna (Italy), aims to localize global disaster management guidelines applied to cultural and environmental heritage. In the context of SIRIUS, a pattern-based OWL 2 DL ontology called the Heritage Risk Assessment Ontology (HeRO) is being developed to standardize risk assessment procedures and manage complex heritage risk data. In this contribution, its effectiveness is demonstrated through an in-depth exposition of its modules and an example scenario, promising practical application in an upcoming web-based tool. Future work involves semantic expansion, alignment with other heritage risk assessment methodologies, and further testing.","tags":null,"title":"HeRO: A Semantic Framework for Heritage Risk Assessment in the SIRIUS Project","type":"publication"},{"authors":["Sebastian Barzaghi"],"categories":null,"content":"","date":1704067200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1704067200,"objectID":"2819e3d275644f24e5852df71e037ce1","permalink":"http://localhost:1313/publication/barzaghi-towards-2024/","publishdate":"2025-02-13T15:40:36.71737Z","relpermalink":"/publication/barzaghi-towards-2024/","section":"publication","summary":"In recent decades, the role of cultural heritage in disaster risk management has been increasingly recognized. However, it is challenging to put in place adequate risk management strategies against possible threats to heritage institutions and the artifacts they work to preserve, manage, and share with both academia and the general public. Challenges include methodological divergences between different communities of experts, an inadequate knowledge of the assets and the inability to evaluate their worth from a non-market perspective, a severe lack of knowledge sharing, a lack of communication between different disciplines involved in heritage risk assessment, and a lack of engagement with local stakeholders. The Heritage Risk Assessment Ontology (HeRO) was developed and re-engineered to standardize risk assessment procedures and manage complex heritage risk data in a FAIR-compliant format. In this contribution, its effectiveness is demonstrated by illustrating its re-engineered structure and an example scenario involving digital preservation. Future work involves increasing its descriptive capabilities and developing a more effective typification mechanism by expanding and aligning existing vocabularies.","tags":["Cultural Heritage","Digital Preservation","FAIR Principles","Heritage Risk Assessment Ontology","Ontology Development","OWL","Risk Assessment"],"title":"Towards a FAIR Ontology Pattern for Describing Heritage Risk Assessment Activities","type":"publication"},{"authors":null,"categories":null,"content":"","date":1701302400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1701302400,"objectID":"b0b0a834a15c223982ed65737737eb33","permalink":"http://localhost:1313/project/hero/","publishdate":"2023-11-30T00:00:00Z","relpermalink":"/project/hero/","section":"project","summary":"The Heritage Risk Assessment Ontology (HeRO) is an OWL 2 DL ontology that aims at providing a framework for modeling machine-readable descriptions of risk assessment activities for heritage risk management. To this end, it leverages, adapts and formalises methodological frameworks widely known in the cultural heritage domain, such as the ABC method.","tags":["Knowledge Management","Data Documentation"],"title":"Heritage Risk Assessment Ontology (HeRO)","type":"project"},{"authors":["Roberto Balzani","Sebastian Barzaghi","Gabriele Bitelli","Federica Bonifazi","Alice Bordignon","Luca Cipriani","Simona Colitti","Federica Collina","Marilena Daquino","Francesca Fabbri","Bruno Fanini","Filippo Fantini","Daniele Ferdani","Giulia Fiorini","Elena Formia","Anna Forte","Federica Giacomini","Valentina Alena Girelli","Bianca Gualandi","Ivan Heibi","Alessandro Iannucci","Rachele Manganelli Del Fà","Arcangelo Massari","Arianna Moretti","Silvio Peroni","Sofia Pescarin","Giulia Renda","Diego Ronchi","Mattia Sullini","Maria Alessandra Tini","Francesca Tomasi","Laura Travaglini","Luca Vittuari"],"categories":null,"content":"","date":1690848000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1690848000,"objectID":"4920523976ca7d86c6426c9fdabbb815","permalink":"http://localhost:1313/publication/balzani-saving-2023/","publishdate":"2025-02-13T15:40:36.786416Z","relpermalink":"/publication/balzani-saving-2023/","section":"publication","summary":"Our goal was to obtain the digital twin of the temporary exhibition \\\"The Other Renaissance: Ulisse Aldrovandi and the Wonders of the World\\\", to make it accessible online to users using various devices (from smartphones to VR headsets). We started with a preliminary assessment of the exhibition, focussing on possible acquisition constraints - time, space, and materials - and related solutions. Then, we proceeded with the creation of the digital twin by acquiring, processing, modelling, optimising, exporting, metadating, and uploading the exhibition. We adopted a hybrid use of two distinct acquisition techniques, i.e. structured light projection scanning and photogrammetry, to create new digital cultural heritage objects and environments, and we used open technologies, formats and protocols to make available the final digital product. We described the process to collect and curate bibliographical (meta)data of the exhibition and digital twin creation process to foster its findability, accessibility, interoperability and reusability.","tags":["Computer Science - Digital Libraries","Computer Science - Graphics"],"title":"Saving temporary exhibitions in virtual environments: the Digital Renaissance of Ulisse Aldrovandi","type":"publication"},{"authors":["Francesca Fabbri","Federica Collina","Sebastian Barzaghi"],"categories":null,"content":"","date":1672531200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1672531200,"objectID":"7599adf7206e8650ffa95844bffb084a","permalink":"http://localhost:1313/publication/fabbri-ai-nodate/","publishdate":"2025-02-13T15:40:36.77058Z","relpermalink":"/publication/fabbri-ai-nodate/","section":"publication","summary":"In the museum sector, interest in visitor engagement methods has been growing for several years. Among these, AI and machine learning have proven to be valid engagement and storytelling tools for museums, in particular for the creation of interactive chatbots and better customize visitor experience. This paper aims to reason about the possibilities of these existing tools, discussing their potential and limitations. The collection of visitor flow data within the museum and the interactive use of chatbots allow different levels of personalization of the visit. The real question is: how can an evolving AI tool be transformed into a storytelling tool that is in harmony with the museum's itinerary and allows for personalization but also respects the museum's own identity and peculiarities? These reflections are part of a research proposal for developing a chatbot to orient visitors within the museum, signaling works of potential interest. The application context is the National Museum of Ravenna, characterised by a vast and heterogeneous collection that is difficult to use.","tags":null,"title":"AI and chatbots as a storytelling tool to personalize the visitor experience. The case of National Museum of Ravenna.","type":"publication"},{"authors":["Sebastian Barzaghi","Federica Collina","Francesca Fabbri","Federica Giacomini","Alice Bordignon","Roberto Balzani","Gabriele Bitelli","Federica Bonifazi","Luca Cipriani","Simona Colitti","Marilena Daquino","Bruno Fanini","Filippo Fantini","Daniele Ferdani","Giulia Fiorini","Elena Formia","Anna Forte","Valentina Alena Girelli","Bianca Gualandi","Ivan Heibi","Alessandro Iannucci","Rachele Manganelli Del Fà","Arcangelo Massari","Arianna Moretti","Silvio Peroni","Sofia Pescarin","Giulia Renda","Diego Ronchi","Mattia Sullini","Maria Alessandra Tini","Francesca Tomasi","Laura Travaglini","Luca Vittuari"],"categories":null,"content":"","date":1672531200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1672531200,"objectID":"0ec21d28f98555b2622c5a25887c52e6","permalink":"http://localhost:1313/publication/barzaghi-digitisation-2023/","publishdate":"2025-02-13T15:40:36.777617Z","relpermalink":"/publication/barzaghi-digitisation-2023/","section":"publication","summary":"Temporary exhibitions in the cultural heritage system have become diffused. They are tools to enhance cultural heritage and to gather, in the same context, cultural goods that otherwise would never be exposed together. Their temporal limitation gives them the uniqueness of an event that will not be repeated. The exhibition \\\"The Other Renaissance: Ulisse Aldrovandi and the Wonders of the World” was created to offer visitors a tour of an exceptional legacy of objects, some of which have never been exhibited before, combined with objects, works of art from several Italian museums, and digital installations that together tell the story of how the first generation of naturalists took their first steps into science as we know it today. To store this exhibition a photogrammetric and structured light scanner survey campaign was launched to acquire 3D objects. By leveraging a combination of 3D, LOD, and Semantic Web technologies, we propose to create a digital twin (intended as an aggregation of different information about real-world heritage objects) of Aldrovandi exhibitions, to create a new digital tool differentiated from the physical exhibition, but that could store all the information and objects exposed together physically.","tags":["CCS Concepts: Human-centered computing→User interface design","Scenario-based design","HCI theory","concepts and models","HCI theory","Human","Scenario","based design","centered computing→User interface design","concepts and models"],"title":"Digitisation of Temporary Exhibitions: the Aldrovandi Case","type":"publication"},{"authors":["Sebastian Barzaghi"],"categories":["Digital Humanities"],"content":"Introduzione Lezione 01 del corso di Digital Humanities e Data Management per i Beni Culturali (2024/2025) Sebastian Barzaghi | sebastian.barzaghi2@unibo.it | https://orcid.org/0000-0002-0799-1527\nPiacere! Ricercatore presso il Dipartimento di Beni Culturali dell’Università di Bologna\nLaureato nel 2020 nel corso di laurea magistrale in Digital Humanities and Digital Knowledge (DHDK) presso l’Università di Bologna\nAttualmente lavoro presso il laboratorio di ricerca FrameLAB e collaboro con altre realtà (es. DHARC)\nFaccio ricerca su come il Semantic Data Modeling e l’Open Science possano migliorare le attività accademiche (ricerca, didattica e terza missione) nei settori delle discipline umanistiche e del patrimonio culturale\nCosa vi aspettate? https://docs.google.com/forms/d/e/1FAIpQLSdL-MvkTUYg3f5AJemIt3n_b2lwUGa1TCYvR_dHAq1mTZwY6w/viewform?usp=sf_link\nDomanda 1? Domanda 2? Domanda 3? Domanda 4? Informazioni preliminari Obiettivi: fornire competenze e strumenti pratici per l’ideazione, gestione e pubblicazione di risorse digitali riguardanti i beni culturali e basate su dati di ambito umanistico\nTemi: Digital Humanities, Gestione dei dati, Modellazione dei dati, Open Science, …\nRisultati: progetti vostri che testimoniano le competenze acquisite\nRegole Materiale integrativo, gratuito e accessibile: i libri e gli articoli sono pensati per essere un accompagnamento alle lezioni e saranno resi disponibili sulla piattaforma istituzionale Virtuale e nella repository GitHub\nPresenza fortemente consigliata: per i non frequentanti ci sarà solo più materiale da studiare; frequentanti: non abbiate paura ad interagire e a fare domande\nProgetto finale: vi verranno forniti dettagli più avanti, ma per il momento sappiate che la natura dell’esame non sarà negoziabile, ma solo il suo contenuto\nOrganizzazione del corso Quando 15 lezioni (lunedì, mercoledì, giovedì) 2 ore per lezione ~ 7 moduli Una sessione teorica e una sessione pratica per ogni modulo 1 pausa di 10 minuti (concordiamo su quando) Dove Lunedì: Aula 2 Mercoledì e giovedì: Laboratorio informatico Come GitHub Virtuale Registrazioni Organizzazione del corso Cosa Cosa sono le Digital Humanities? Cosa sono i dati umanistici? Cos’è l’Open Science? Cosa sono i Linked Open Data? Cos’è il Data Management? Pianificare Raccogliere Processare Analizzare Descrivere Pubblicare Come fare tutto questo? Esame Un progetto originale di gestione dei dati correlato a tematiche di interesse documentario e/o storico-artistico, che verrà presentato durante un colloquio orale (e pubblicato su GitHub)\nBasato su linee guida specifiche che saranno presentate e discusse durante il corso e che saranno disponibili su Virtuale e nel repository GitHub\nGli studenti potranno lavorare al progetto individualmente o in gruppo (massimo 3 persone)\nPreparazione all’esame Non spaventatevi: avremo modo di esercitarci e capire assieme i vari passaggi da seguire per realizzare un buon progetto (e portare a casa un 30 e lode)\nNelle sessioni pratiche, lavoreremo assieme su un progetto giocattolo di gestione dei dati in cui io parteciperò attivamente e voi avrete già modo di sperimentare con gli strumenti e i metodi che vi presenterò a lezione\nValutazione Il contributo personale di ciascuna persona e la conoscenza degli argomenti del corso saranno valutati durante il colloquio orale\n\u0026lt;50% (valutazione negativa): preparazione non adeguata in nessun aspetto del progetto 51-70% (valutazione sufficiente): preparazione accettabile in almeno uno degli aspetti del progetto (punteggio compreso tra 18/30 e 23/30) 71-90% (valutazione positiva): preparazione adeguata in tutti gli aspetti del progetto (punteggio compreso tra 24/30 e 27/30) 91-100% (valutazione eccellente): ottima preparazione in tutte le parti della verifica e possiede significative capacità di elaborazione critica degli argomenti trattati (punteggio compreso tra 28/30 e 30/30) Valutazione Ad un certo punto, anche voi dovrete valutare me :P\nVi prego di essere quanto più correttti ed oggettivi possibile nella valutazione del corso, in modo da farmi capire cosa va bene e cosa no\nRaccomandazioni finali Affrontare cose nuove è sempre difficile, quindi non preoccupatevi se il corso può sembrare complicato: lo è, perché di base si tratta di tematiche difficili, ma l’ho pensato cercando di renderlo accessibile ai non addetti ai lavori (perchiò una vostra valutazione onesta è assolutamente fondamentale)\nSe fatte in buona fede, non esistono domande stupide\nNel dubbio, chiedete sempre: a seconda della domanda, potrei aver bisogno di tempo per darvi una risposta sensata, quindi nel caso abbiate un po’ di pazienza :P\nFine Lezione 01 del corso di Digital Humanities e Data Management per i Beni Culturali (2024/2025) Sebastian Barzaghi | sebastian.barzaghi2@unibo.it | https://orcid.org/0000-0002-0799-1527\n","date":1672444800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1672444800,"objectID":"6d8db8caf93c4b8e8e3d9d34376c8ae1","permalink":"http://localhost:1313/slides/dhdmch-00/","publishdate":"2022-12-31T00:00:00Z","relpermalink":"/slides/dhdmch-00/","section":"slides","summary":"L'introduzione al corso di Digital Humanities e Data Management per i Beni Culturali","tags":["Digital Humanities"],"title":"DHDMCH - Introduzione","type":"slides"},{"authors":null,"categories":null,"content":"","date":1638921600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1638921600,"objectID":"834c9ff8f150f1406a9bcb964e1c2a1f","permalink":"http://localhost:1313/project/moro/","publishdate":"2021-12-08T00:00:00Z","relpermalink":"/project/moro/","section":"project","summary":"The National Edition of Aldo Moro’s works is a critical digital edition of the published and unpublished texts of the famous Italian politician. It aims to provide a cultural product that is universally available to all citizens and propose a new standard for national and international research in political communication.","tags":["Digital Editions"],"title":"National Edition of Aldo Moro's works","type":"project"},{"authors":["Sebastian Barzaghi"],"categories":null,"content":"","date":1635724800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1635724800,"objectID":"3950f4a50e39e56c9c37b5f3238f23e1","permalink":"http://localhost:1313/publication/barzaghi-controlled-2021-2/","publishdate":"2025-02-13T15:40:36.823018Z","relpermalink":"/publication/barzaghi-controlled-2021-2/","section":"publication","summary":"A SKOS controlled vocabulary of the possible roles assumed by Aldo Moro during his lifetime. https://www.w3id.org/moro/voc/roles/ is the namespace of the vocabulary. Its preferred prefix is `mrv`. The naming convention `prefix:elementnumber ̀does not strictly convey meaning per se, but it has been followed to avoid excessively long URIs. In order to understand the meaning of any concept, please refer to its respective documentation properties, such as `skos:prefLabel`. The vocabulary imports the Publication Roles Ontology (PRO, http://purl.org/spar/pro), in order to take advantage of its classes and properties, by aligning the class `mrv:Role` as a subclass of `pro:Role`.","tags":["controlled vocabulary","digital edition","digital humanities","knowledge organization","national edition of aldo moro's works","semantic web","skos"],"title":"Controlled vocabulary of Aldo Moro's roles","type":"publication"},{"authors":["Sebastian Barzaghi"],"categories":null,"content":"","date":1635724800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1635724800,"objectID":"79163a0986d031ccabc5d893d8d72600","permalink":"http://localhost:1313/publication/barzaghi-controlled-2021-1/","publishdate":"2025-02-13T15:40:36.816123Z","relpermalink":"/publication/barzaghi-controlled-2021-1/","section":"publication","summary":"A SKOS controlled vocabulary of the possible subjects covered in Aldo Moro's works. https://www.w3id.org/moro/voc/subjects/ is the namespace of the vocabulary. Its preferred prefix is `msv`. The naming convention `prefix:elementnumber ̀does not strictly convey meaning per se, but it has been followed to avoid excessively long URIs. In order to understand the meaning of any concept, please refer to its respective documentation properties, such as `skos:prefLabel`.","tags":["controlled vocabulary","digital edition","digital humanities","knowledge organization","national edition of aldo moro's works","semantic web","skos"],"title":"Controlled vocabulary of Aldo Moro's works subjects","type":"publication"},{"authors":["Sebastian Barzaghi"],"categories":null,"content":"","date":1635724800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1635724800,"objectID":"afd59ab497616c081d372368bbca0a31","permalink":"http://localhost:1313/publication/barzaghi-controlled-2021/","publishdate":"2025-02-13T15:40:36.809275Z","relpermalink":"/publication/barzaghi-controlled-2021/","section":"publication","summary":"A SKOS controlled vocabulary of the possible document types of Aldo Moro's works. https://www.w3id.org/moro/voc/types/ is the namespace of the vocabulary. Its preferred prefix is `mtv`. The naming convention `prefix:elementnumber ̀does not strictly convey meaning per se, but it has been followed to avoid excessively long URIs. In order to understand the meaning of any concept, please refer to its respective documentation properties, such as `skos:prefLabel`.","tags":["controlled vocabulary","digital edition","digital humanities","knowledge organization","national edition of aldo moro's works","semantic web","skos"],"title":"Controlled vocabulary of Aldo Moro's works types","type":"publication"},{"authors":["Sebastian Barzaghi"],"categories":null,"content":"","date":1635724800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1635724800,"objectID":"d29d1b2b4205c3040f82348e4540c014","permalink":"http://localhost:1313/publication/barzaghi-source-2021/","publishdate":"2025-02-13T15:40:36.802404Z","relpermalink":"/publication/barzaghi-source-2021/","section":"publication","summary":"A collection of the source codes used to automatically register the Digital Object Identifiers of the works published on the National Edition of Aldo Moro's works. The software connects to both an external MongoDB database and the DataCite API in order to assign to each document its respective DOI and register it on DataCite Fabrica. To start the program, fill in the blanks in the code (marked with '@') accordingly, then run `python doifier.py` in the command prompt, and select the HTTP method to run.","tags":["datacite","digital edition","digital object identifier","national edition of aldo moro's works","python"],"title":"Source code for generating the National Edition of Aldo Moro's works DOIs","type":"publication"},{"authors":["Sebastian Barzaghi"],"categories":null,"content":"","date":1635724800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1635724800,"objectID":"cb0ed6aaf91a575f15d7aeee1e6d35e0","permalink":"http://localhost:1313/publication/barzaghi-source-2021-1/","publishdate":"2025-02-13T15:40:36.83006Z","relpermalink":"/publication/barzaghi-source-2021-1/","section":"publication","summary":"A Python script used to convert introductions and historical-critical notes, prepared by researchers and curators, into PDF files. The `stylesheet.css` file is used to define the style of the PDF output. You will either need a `config.json` file containing some variables in order to make it work (such as your local path and the name of the directory containing the HTML essays), or write them directly into the code as variables.","tags":["digital edition","digital humanities","national edition of aldo moro's works","python"],"title":"Source code for PDF conversion of introductory essays in the National Edition of Aldo Moro's works","type":"publication"},{"authors":["Sebastian Barzaghi"],"categories":null,"content":"","date":1633046400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1633046400,"objectID":"9f28e952126b885b51349267d2c24848","permalink":"http://localhost:1313/publication/barzaghi-national-2021/","publishdate":"2025-02-13T15:40:36.844625Z","relpermalink":"/publication/barzaghi-national-2021/","section":"publication","summary":"A Turtle file that contains structural, intertextual and contextual data about the National Edition of Aldo Moro's works.","tags":["digital edition","digital humanities","national edition of aldo moro's works","rdf","semantic web","turtle"],"title":"National Edition of Aldo Moro's works (RDF Dataset)","type":"publication"},{"authors":["Sebastian Barzaghi"],"categories":null,"content":"","date":1633046400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1633046400,"objectID":"7c1ebc16e70587e04e9ad2cc7b43a0df","permalink":"http://localhost:1313/publication/barzaghi-source-2021-2/","publishdate":"2025-02-13T15:40:36.836984Z","relpermalink":"/publication/barzaghi-source-2021-2/","section":"publication","summary":"A series of Python scripts that have been used to process the documents in the National Edition of Aldo Moro's works.  In particular, the scripts are: recast.py, for refactoring the documents code, correcting possible errors, normalizing and finalizing resource URIs, and so on; TEIfy.py, for generating TEI documents from the HTML code. The TEI structure imitates the source code as closely as possible, and in addition integrates bibliographic metadata in the document header as well; PDFfy.py, for generating PDF documents from the HTML code. The PDF pagination and visualization is regulated by a CSS stylesheet (stylesheet.css); generate.py, for converting metadata into semantic statements collected in a knowledge base and organized on the basis of the standards defined in the data modelling phase; align.py, for integrating document markup in the knowledge base; main.py, for gathering and managing the functions defined in the other scripts; utils.py, for choosing which script to run and in which local directory. To start the program, run `python main.py` in the command prompt, then select the function you want to run and the directory you intend to use. You will either need a `config.json` file containing some variables in order to make it work (such as your local paths and names of the directories), or write them directly into the code as variables.","tags":["data cleaning","data wrangling","digital edition","digital humanities","national edition of aldo moro's works","python","semantic web"],"title":"Source code for processing the National Edition of Aldo Moro's works data","type":"publication"},{"authors":["Sebastian Barzaghi"],"categories":null,"content":"","date":1627776000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1627776000,"objectID":"fdb218534b507da8f6ce0a7e959895fb","permalink":"http://localhost:1313/publication/barzaghi-protocol-2021/","publishdate":"2025-02-13T15:40:36.879601Z","relpermalink":"/publication/barzaghi-protocol-2021/","section":"publication","summary":"This work aims to define a series of reference models that would serve as a guide to the design and development of the National Edition of Aldo Moro's works. These models ha...","tags":null,"title":"Protocol of the competitive audit for designing and developing the National Edition of Aldo Moro's works","type":"publication"},{"authors":["Sebastian Barzaghi"],"categories":null,"content":"","date":1625097600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1625097600,"objectID":"60c10af289f353af93af214bc8342a22","permalink":"http://localhost:1313/publication/barzaghi-modellazione-2021/","publishdate":"2025-02-13T15:40:36.872336Z","relpermalink":"/publication/barzaghi-modellazione-2021/","section":"publication","summary":"L’Edizione nazionale delle opere di Aldo Moro è un’edizione critica, filologicamente avvertita e annotata, dei testi editi ed inediti dello statista, che punta non solo a fornire un prodotto culturale universalmente fruibile dai cittadini, ma anche a realizzare un nuovo standard per la ricerca nazionale e internazionale sulla comunicazione politica. L'Edizione è realizzata interamente su piattaforma digitale ed è interrogabile in modo selettivo secondo molteplici criteri differenti basati su elementi intertestuali e contestuali delle opere, individuati dai ricercatori che ne hanno curato l’annotazione e la metadatazione. L’obiettivo di questo documento è quello di descrivere il processo di modellazione dei dati dell’Edizione. In particolare, questo documento si concentra sulla presentazione dei modelli principalmente utilizzati per descrivere le informazioni testuali, contestuali, e bibliografiche delle opere. Sebbene si tratti di un processo di modellazione basato sulle particolari necessità informative del Comitato Scientifico e della comunità scientifica interessata alla vita e all’operato di Aldo Moro, altri individui possono beneficiare di questo documento, che definisce un esempio di modellazione concettuale facilmente replicabile anche in altri contesti accademici e progettuali.","tags":null,"title":"La modellazione dei dati nell'Edizione Nazionale delle Opere di Aldo Moro","type":"publication"},{"authors":["Sebastian Barzaghi"],"categories":null,"content":"","date":1619827200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1619827200,"objectID":"b3e23681a2f12edaa8ad09b9d71d7157","permalink":"http://localhost:1313/publication/barzaghi-benchmark-2021/","publishdate":"2025-02-13T15:40:36.794907Z","relpermalink":"/publication/barzaghi-benchmark-2021/","section":"publication","summary":"The dataset collects a series of values associated with a sample of 30 digital editions, and based on some evaluation criteria for reviewing scholarly digital editions compiled by Patrick Sahle in collaboration with Georg Voegler and IDE (Institut für Dokumentologie und Editorik) members (Sahle 2014). In particular, the aspects that have been taken into consideration during the evaluation process are the following: Documentation (Documentation, Scholarly objectives, Mission focusing on the objectives, Documentation and associated texts); Audience (Mission, focusing on the audience); Representation (Representation of documents and texts); Data model (Data modelling); Browse; Search; Indices; Quality of the presentation; Metadata (Metadata for description of and interlinkage between objects in the edition); Identification (Identification and citation); Formats (Spin offs and export formats); OS-OA (Access to basic data, Rights and licences); Additional features; Each aspect (except for Audience and Data model) has been given a score between 0, 0.5, and 1, where: 0 represents a value that witnesses either the total absence or the lack of quality of the edition in terms of that specific aspect; 0.5 represents a value that witnesses a suboptimal implementation of that specific aspect in the edition; 1 represents a value that witnesses an optimal implementation of that specific aspect in the edition.","tags":["benchmark","digital editions","digital humanities"],"title":"Benchmark Dataset for designing and developing the National Edition of Aldo Moro's works","type":"publication"},{"authors":["Sebastian Barzaghi"],"categories":null,"content":"","date":1619827200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1619827200,"objectID":"af95260dda3b6e66f20c55b5c4dd71a8","permalink":"http://localhost:1313/publication/barzaghi-competitive-2021/","publishdate":"2025-02-13T15:40:36.864968Z","relpermalink":"/publication/barzaghi-competitive-2021/","section":"publication","summary":"This work aims to define a series of reference models that would serve as a guide to the design and development of the National Edition of Aldo Moro's works. These models have been defined through a benchmarking process that is organized as follows: content analysis on a sample of 30 digital editions, evaluated on the basis of certain criteria defined in [Sahle 2014]; processing of the data gathered as a result of the content analysis, so as to extract the relevant information, and visualize it; review of the data processing results and consideration of the models that can be used as reference. The digital editions that meet the quality criteria taken into consideration are equipped with the following characteristics: their audience is composed of both domain experts and generic users; their documentation is rich and accurate; their content is described by a complete set of metadata; they and their single parts are citable and uniquely identifiable; their data model is geared towards interoperability and interlinking between its contents and the relevant resources already existing on the Web; they use visualization and storytelling tools so as to convey information intuitively; their information architecture is well-structured and easily navigated; their data and contents can be downloaded in many different formats; they take advantage of Open Source software and tools; finally, their contents are open and accessible to anyone.","tags":null,"title":"Competitive audit for designing and developing the National Edition of Aldo Moro's works","type":"publication"},{"authors":null,"categories":null,"content":"MeMO, the Medieval Manuscripts Ontology, is an OWL 2 DL ontology that aims to provide a framework for the formal description of the medieval codices and manuscripts described in the Project IRNERIO catalogue and the relations that exist between them. It is centered on a set of concepts (codex, manuscript, folio, text and gloss), which have been precisely defined via the Functional Requirements for Bibliographic Records (FRBR) standard in order to model such complexity in an accurate and logically consistent structure. The model thus becomes able to cover multiple use cases and scenarios in proportion to how many requirements have been adequately met.\nWhile developing MeMO, a high priority has been given to the goal of reaching a sound balance between precision (to satisfy the user’s needs) and coverage (to ensure a certain degree of extensibility and reuse) of the model. Ultimately, the idea behind the development of MeMO has been to provide a data model for representing the aforementioned collection of medieval codices and manuscripts according to certain requirements and with the possibility to extend it for representing similar resources that exist in other collections.\nFRBR allows a holistic perspective about the resource, on multiple levels of conceptualization, by breaking down the semantic and conceptual ambiguities related to objects created by human hands into different but related and layered concepts and by allowing the description of an artifact and its relations with other entities to be more expressive, precise and dynamic. Nonetheless, FRBR has some limitations. Even though the definitions of its concepts are quite straightforward, FRBR is not easily understood by the common user, who finds the terms work, expression, manifestation and item not very clear.\nAccording to FRBR, any object (such as a manuscript, for example) has to be described by taking into consideration all the four levels in order to have a complete overview of it. This multi-leveled conceptualization is difficult for an average user to comprehend, because it is much more intuitive to expect the concept of that object to exist at a single FRBR level. In order to avoid this issue without giving up the expressivity of FRBR, a good solution is to place that object at the level that is deemed more appropriate in relation to the scenario taken into consideration.\nThis approach has been used systematically for the FRBR-aligned Bibliographic Ontology (FaBiO) (Peroni and Shotton 2012), with which MeMO has been aligned. Being an ontology focused on entities that are published, textual in nature, and/or referred to by bibliographic references, FaBiO defines its own set of entities that are subclasses of the original FRBR entities by taking advantage of the FRBRcore RDF vocabulary (FRBRcore, http://purl.org/vocab/frbr/core#). In order to embrace this approach and be consistent with the scenarios that are present in the case study, MeMO reuses FaBiO interpretations of FRBR entities as superclasses of its entities. In particular: manuscript, text and gloss are conceptualized as subclasses of fabio:Expression (since they are carry a content and are not inherently related to a precise format), while codex and folio are conceptualized as subclasses of fabio:Manifestation, since they carry a format that functions as a container for both text and glosses, and thus for manuscripts as well.\n","date":1584662400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1584662400,"objectID":"96a903923dc715add541dda3e30ff43e","permalink":"http://localhost:1313/project/memo/","publishdate":"2020-03-20T00:00:00Z","relpermalink":"/project/memo/","section":"project","summary":"The Medieval Manuscripts Ontology (MeMO) is an OWL 2 DL ontology that aims to provide a framework for the formal description of the collection of medieval codices and manuscripts. It has been developed in the context of Progetto IRNERIO, according to certain requirements and with the possibility to extend it for representing similar resources that exist in other collections.","tags":["Knowledge Management","Data Documentation"],"title":"Medieval Manuscript Ontology (MeMO)","type":"project"},{"authors":["Sebastian Barzaghi","Monica Palmirani","Silvio Peroni"],"categories":null,"content":"","date":1577836800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1577836800,"objectID":"5aef5669d80066c74ac9a89dddcd8979","permalink":"http://localhost:1313/publication/barzaghi-development-2020/","publishdate":"2025-02-13T15:40:36.886019Z","relpermalink":"/publication/barzaghi-development-2020/","section":"publication","summary":"","tags":null,"title":"Development of an ontology for modelling medieval manuscripts: the case of Progetto IRNERIO","type":"publication"},{"authors":["Francesca Tomasi","Marilena Daquino","Sebastian Barzaghi"],"categories":null,"content":"","date":1577836800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1577836800,"objectID":"398bffa59797eae4590fe02ccf3b1584","permalink":"http://localhost:1313/publication/tomasi-vespasiano-2020/","publishdate":"2025-02-13T15:40:36.89193Z","relpermalink":"/publication/tomasi-vespasiano-2020/","section":"publication","summary":"Edizione digitale semantica delle Lettere di Vespasiano da Bisticci, comprensiva di: dataset, applicazione, documentazione","tags":["M-STO/08 Archivistica","bibliografia e biblioteconomia","PE6_10 Web and information systems","database systems","information retrieval and digital libraries","data fusion","SH5_11 Cultural heritage","cultural memory"],"title":"Vespasiano da Bisticci, Lettere. Knowledge Base 2020","type":"publication"},{"authors":["Alessandra Auddino","Sebastian Barzaghi","Anna Bernabè","Daniele Cavestri","Alessandra Foschi","Caterina Franchi","Ivan Heibi","Francesca Mangialardo","Fabio Mariani","Silvio Peroni","Gianmarco Spinaci"],"categories":null,"content":"","date":1561939200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1561939200,"objectID":"c7299dad49f7c4c9cc332e8dfb1efe61","permalink":"http://localhost:1313/publication/auddino-conformita-2019/","publishdate":"2025-02-13T15:40:36.857854Z","relpermalink":"/publication/auddino-conformita-2019/","section":"publication","summary":"Questo documento presenta un'analisi delle 39 riviste scientifiche online, dichiarate Open Access, a disposizione attraverso la piattaforma gestita dal servizio AlmaDL Journals dell'Università di Bologna, al fine di verificarne la compatibilità con la Open Definition.","tags":null,"title":"Conformità all'Open Access delle riviste pubblicate dall'Università di Bologna","type":"publication"},{"authors":["Daniele Cavestri","Francesca Mangialardo","Sebastian Barzaghi","Silvio Peroni"],"categories":null,"content":"","date":1561939200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1561939200,"objectID":"cad43fcb58941ccd9e319efe87fdebcc","permalink":"http://localhost:1313/publication/cavestri-protocollo-2019/","publishdate":"2025-02-13T15:40:36.851411Z","relpermalink":"/publication/cavestri-protocollo-2019/","section":"publication","summary":"Questo protocollo è stato utilizzato per indagare la legittimità della definizione “Open Access Scientific Journals” indicata per le riviste curate dai Dipartimenti e dai...","tags":null,"title":"Protocollo di Conformità di Riviste Scientifiche all Open Access","type":"publication"}]